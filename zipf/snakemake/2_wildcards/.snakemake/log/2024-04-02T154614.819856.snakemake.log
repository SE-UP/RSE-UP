Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job                         count
------------------------  -------
count_words                     1
count_words_frankenstein        1
count_words_sherlock            1
zipf_test                       1
total                           4

Select jobs to execute...
Execute 3 jobs...

[Tue Apr  2 15:46:14 2024]
localrule count_words:
    input: ../wordcount.py, ../../data/dracula.txt
    output: ../../results/dracula.dat
    jobid: 1
    reason: Missing output files: ../../results/dracula.dat
    resources: tmpdir=/tmp


[Tue Apr  2 15:46:14 2024]
localrule count_words_frankenstein:
    input: ../wordcount.py, ../../data/frankenstein.txt
    output: ../../results/frankenstein.dat
    jobid: 2
    reason: Missing output files: ../../results/frankenstein.dat
    resources: tmpdir=/tmp


[Tue Apr  2 15:46:14 2024]
localrule count_words_sherlock:
    input: ../wordcount.py, ../../data/sherlock_holmes.txt
    output: ../../results/sherlock_holmes.dat
    jobid: 3
    reason: Missing output files: ../../results/sherlock_holmes.dat
    resources: tmpdir=/tmp

[Tue Apr  2 15:46:14 2024]
Finished job 2.
1 of 4 steps (25%) done
[Tue Apr  2 15:46:14 2024]
Finished job 3.
2 of 4 steps (50%) done
[Tue Apr  2 15:46:14 2024]
Finished job 1.
3 of 4 steps (75%) done
Select jobs to execute...
Execute 1 jobs...

[Tue Apr  2 15:46:14 2024]
localrule zipf_test:
    input: ../../results/dracula.dat, ../../results/frankenstein.dat, ../../results/sherlock_holmes.dat
    output: ../../results/wildcards_zipf_results.txt
    jobid: 0
    reason: Missing output files: ../../results/wildcards_zipf_results.txt; Input files updated by another job: ../../results/frankenstein.dat, ../../results/dracula.dat, ../../results/sherlock_holmes.dat
    resources: tmpdir=/tmp

[Tue Apr  2 15:46:14 2024]
Finished job 0.
4 of 4 steps (100%) done
Complete log: .snakemake/log/2024-04-02T154614.819856.snakemake.log
